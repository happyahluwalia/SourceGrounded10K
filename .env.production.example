# Production Environment Configuration
# Copy this to .env and update with your actual values

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================
APP_NAME=10kiq
DOMAIN=10kiq.com
DEBUG=false
LOG_LEVEL=INFO
ENABLE_DEBUG_LOGS=false

# ============================================================================
# SECURITY
# ============================================================================
# Comma-separated list of allowed origins (auto-configured from DOMAIN)
CORS_ORIGINS=https://10kiq.com,https://www.10kiq.com,http://localhost:3000

# API key for authentication (currently not implemented - reserved for future use)
# Will be auto-generated by gpu_deploy.sh
API_KEY=your_secure_api_key_here_change_this

# Rate limiting
RATE_LIMIT_PER_MINUTE=10
RATE_LIMIT_PER_HOUR=100

# ============================================================================
# DATABASE - PostgreSQL
# ============================================================================
DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/financeagent

# Postgres container settings
POSTGRES_DB=financeagent
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here_change_this

# ============================================================================
# VECTOR DATABASE - Qdrant
# ============================================================================
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=financial_documents

# ============================================================================
# CACHE - Redis
# ============================================================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ============================================================================
# LLM - Ollama
# ============================================================================
OLLAMA_BASE_URL=http://ollama:11434

# Production LLM Model (choose one):
# - phi3:mini-instruct (recommended: 3.8B params, stable on 8GB RAM)
# - llama3.1:8b-instruct (higher quality, needs monitoring on 8GB RAM)
OLLAMA_MODEL=phi3:mini-instruct

# ============================================================================
# EMBEDDINGS
# ============================================================================
# Production embedding model
# nomic-embed-text-v1.5: 768-dim, 8K context window, optimized for long docs
EMBEDDING_MODEL=nomic-embed-text-v1.5
EMBEDDING_DIMENSION=768

# ============================================================================
# CHUNKING STRATEGY
# ============================================================================
# Context window math for phi3 (4K tokens):
# - 5 chunks × 1024 chars/chunk = 5,120 chars
# - 5,120 chars ÷ 4 chars/token ≈ 1,280 tokens (31% of context)
# - Prompt overhead: ~200 tokens
# - Answer: 500 tokens
# - Total: ~1,980 tokens (48% utilization, leaves 2K buffer)
CHUNK_SIZE=1024
CHUNK_OVERLAP=150

# ============================================================================
# RAG SETTINGS
# ============================================================================
TOP_K=5                    # Number of chunks to retrieve from Qdrant
SCORE_THRESHOLD=0.5        # Minimum similarity score (0-1)
MAX_TOKENS=500             # Maximum tokens in LLM response

# ============================================================================
# BATCH PROCESSING
# ============================================================================
EMBEDDING_BATCH_SIZE=32           # Batch size for embedding generation
QDRANT_UPLOAD_BATCH_SIZE=100      # Batch size for Qdrant uploads

# ============================================================================
# SEC EDGAR API
# ============================================================================
# Required by SEC: Format "FirstName LastName email@domain.com"
# SEC will block requests without proper User-Agent
SEC_USER_AGENT=YourFirstName YourLastName your.email@example.com

# ============================================================================
# NOTES FOR DEPLOYMENT
# ============================================================================
# 
# 1. BEFORE DEPLOYING:
#    - Change all passwords and API keys
#    - Update CORS_ORIGINS with your actual domain
#    - Update SEC_USER_AGENT with your real name and email
#
# 2. PULL MODELS FIRST:
#    docker exec -it financeagent_ollama ollama pull nomic-embed-text
#    docker exec -it financeagent_ollama ollama pull phi3:mini-instruct
#
# 3. RECREATE QDRANT COLLECTION (dimension changed 1024 → 768):
#    curl -X DELETE http://localhost:6333/collections/financial_documents
#    docker-compose restart app
#
# 4. MEMORY MONITORING (8GB Droplet):
#    - Phi-3: ~3GB (safe, recommended)
#    - Llama 3.1: ~6GB (monitor closely)
#    - Total system: should stay under 6GB
#
# 5. VERIFY SETUP:
#    docker exec -it financeagent_app python scripts/verify_production_models.py
#
# ============================================================================
